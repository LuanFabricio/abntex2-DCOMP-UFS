\chapter{Experimentos e resultados}

Neste capítulo serão apresentados os experimentos feitos durante o TCC. Eles tiveram como
finalidade avaliar o uso de métodos e técnica de compressão de modelos, focado em dispositivos
embarcados. Nele serão apresentados os métodos de avaliação do modelo (\autoref{sec_avaliacao_modelo}),

\section{Dispositivo utilizado}\label{sec_dispositivo}
O ESP32-S3 N16R8 foi escolhido como dispositivo utilizado pelo seu custo-benefício, sendo um aparelho poderoso
considerando o seu baixo custo e consumo energético. Além disso, esse modelo possui u TERMINAR

\section{Modelo utilizado}\label{sec_modelo_utilizado}
O modelo utilizado foi o MobileFaceNet, pois ele mantém uma acurácia acima de 90\% na tarefa de detecção de faces,
com tempo de inferência e baixa pegada de memória \cite{leandro}.

\section{Método de treinamento do modelo}\label{sec_treinamento_modelo}
Para fazer o treinamento dos modelos, foi necessário utilizar a técnica de \textit{triplet distillation}
\cite{triplet_distillation_face_recognition},
para que seja possível medir o quão próximo as \textit{embeddings} de uma imagem são parecidas com as de outra.
Essa técnica usa três imagens, \textbf{âncora}, que é considerada como imagem base, \textbf{positiva},
que é uma variação da mesma categoria da âncora, e \textbf{negativa}, de outra categoria.

No contexto de reconhecimento facial, a âncora e positi

\subsection{\textit{Triplet Loss}}
Para realizar o treinamento do modelo MobileFaceNet, foi utilizada a técnica \textit{triplet loss}
\cite{triplet_distillation_face_recognition}. Ela tem como objetivo comparar os \textit{embeddings} de três imagens,
utilizando a distância de cosseno ($D$) de um embedding ($x_i^j$) comparado com outro ($x_i^k$).
%Essa técnica utiliza é descrita pela fórmula \ref{eq_triplet_loss}

\begin{equation}\label{eq_triplet_loss}
	Loss = \frac 1 N \sum _i ^N max(D(x_i^a, x_i^p) - D(x_i^a, x_i^n) + m, 0))
\end{equation}
%
% \begin{equation}\label{eq_triplet_loss_teacher_dist}
% 	d = max(T(x_i^a, x_i^n) - T(x_i^a, x_i^p), 0)
% \end{equation}
%

Na equação \ref{eq_triplet_loss}, é a função \textit{Loss} utilizada para treinar o modelo. Onde, $x_i^a$ é
a imagem âncora, $x_i^p$ é a imagem positiva e $x_i^n$ é a imagem negativa, todas referentes a i-ésima
tripla e $m$ é um hiperparâmetro que define a margem entre o par positivo e par negativo.
Então, quanto mais parecidos forem os \textit{embeddings} da imagem âncora com a imagem positiva,
menor será a perda, sendo o inverso para a âncora com a imagem negativa.

\subsection{\textit{Triplet Distillation}}
Para realizar o treinamento dos modelos MobileNetV3 e Rafael-2, foi utilizada a técnica de
\textit{Knowledge Distillation} \cite{hinton2015distilling} com \textit{Triplet Loss}, conhecida como
\textit{triplet loss} \cite{triplet_distillation_face_recognition}.
Ela utiliza cálculo da \textit{Loss Function} (\ref{eq_triplet_loss}) como base, adicionando a distância entre os
\textit{embeddings} do modelo estudante e do modelo professor, como pode ser visto na fórmula
\ref{eq_triplet_distillation}.

\begin{equation}\label{eq_triplet_distillation}
	Loss = \frac 1 N \sum _i ^N max(D(x_i^a, x_i^p) - D(x_i^a, x_i^n) + d, 0))
\end{equation}

\begin{equation}\label{eq_triplet_loss_teacher_dist}
	d = max(T(x_i^a, x_i^n) - T(x_i^a, x_i^p), 0)
\end{equation}

Onde $T$ (\ref{eq_triplet_loss_teacher_dist}) é a distância entre os \textit{embeddings} do modelo estudante e
professor, e $d$ (\ref{eq_triplet_distillation}) é utilizado como uma margem dinâmica entre par positivo e negativo.

% TODO:
% - Citar modelos treinados (Triplet Distillation)
% 	- Rafael
% 	- MobileNetV3Small

\section{Método de avaliação}\label{sec_avaliacao_modelo}
Para avaliar o modelo, primeiro, as características de cada imagem e sua versão espelhada
(\textit{flip} horizontal) são extraídas pelo modelo. Depois é realizada a verificação da face,
calculando a distância de cosseno entre os vetores de características
\cite{triplet_distillation_face_recognition}, onde a imagem com menor distância é considerada a previsão do
modelo.

TODO: ADICIONAR IMAGEM
% TODO: DETALHAR

\section{\textit{Datasets}}\label{sec_datasets}

\subsection{\textit{Labeled Faces in the Wild} (LFW)}
Este \textit{dataset} possui imagens da face de várias celebridades, classificadas com o nome da pessoa.
Para esse trabalho, foi utilizada uma variação do LFW, que agrupa as imagens em triplas, \textbf{âncora},
\textbf{positiva} e \textbf{negativa}, para ser utilizado como dataset de treinamento, seguindo a técnica
de \textit{triplet distillation} \cite{triplet_distillation_face_recognition}.


Para realizar o treinamento do modelo, foi utilizada uma variação do \textit{dataset}
\textit{Labeled faces in the Wild} (LFW), que possui várias amostras contendo triplas com as imagens das faces,
assim facilitando o uso da técnica de \textit{triplet distillation} para o treinamento.

TODO: ADICIONAR DATASET DA UFS (LEANDRO)

\subsection{Faces - UFS}
Este \textit{dataset} possui faces coletadas de alunos da Universidade Federal de Sergipe (UFS) \cite{leandro}.
Ele foi utilizado na etapa de validação (\ref{sec_avaliacao_modelo}).

\section{Resultados}\label{sec_resultados}

\subsection{Métricas usadas}\label{sect_restultados_metricas}
Para avaliar o desempenho, foram utilizadas as métricas de precisão (\ref{sect_restultados_metricas_precisao})
e acurácia (\ref{sect_restultados_metricas_acuracia})

\subsubsection{Precisão}\label{sect_restultados_metricas_precisao}

\subsubsection{Acurácia}\label{sect_restultados_metricas_acuracia}

---

Neste capítulo serão apresentados testes feitos durante o período inicial do TCC, eles tiveram a finalidade de aplicar técnicas para ter modelos menores.
O objetivo principal é aplicar as técnicas de compressão para criar modelos menores e computacionalmente eficientes.

% Destilação de conhecimento
\section{Destilação de conhecimento (modelo Professor-Aluno)}
Para fazer o experimento com destilação de conhecimento foi utilizada a base STL-10 \cite{stl10}, que possui 500 imagens para
treinamento e 800 para teste, com resolução de $96 \times 96$ e 3 canais de cor (RGB). Como o conjunto de dados
não possui muitas imagens, foi aplicada a técnica de \textit{data augmentation} (aumento de dados) para reduzir o
\textit{overfitting}.

Como já descrito na \autoref{conceitos_destilacao}, o objetivo dessa etapa é utilizar o conhecimento do modelo
Professor (mais robusto e pré-treinado) para treinar o modelo Aluno (mais simples e sem pré-treinamento).
O modelo professor (\autoref{res_professor}) é a ResNet-50  \cite{resnet} e o modelo estudante é gerado pelo
% NOTE: Movo para o texto?
\autoref{res_aluno_1}.
Além disso, o modelo Rafael \cite{rafael} foi adaptado e utilizado (com algumas variações).

% TODO: Continuar correção
Para aumentar a precisão do modelo Aluno com o destilação de conhecimento, foi utilizada a otimização
Bayesiana, para procurar os valores dos hiperparâmetros $\alpha$ e \textit{Temperature}.
% TODO: Revisar
% Talvez mover pro capítulo 02
% Onde $\alpha$ é o peso da \textit{loss function} do modelo estudante e \textit{Temperature} é a relação de
% \textit{logits} da função \textit{softmax}.
Os possíveis valores de $\alpha$ foram 0.1, 0.5, 0.01 e 0.25.
E os possíveis valores de \textit{Temperature} foram 2, 5, 7, 10, 12, 15, 17 e 20.
Os resultados do experimento estão na \autoref{tabela_acuracia_1}.

% TODO: Continuar correção
\begin{center}
\begin{table}[htb]
\centering
\ABNTEXfontereduzida
\caption[Acurácia dos modelos]{Acurácia dos modelos.}
\label{tabela_acuracia_1}
\begin{tabular}{ |c|c|c|c|c| }
	\hline
	\textbf{Modelo} & \textbf{Com destilação de conhecimento?}  & \textbf{Acurácia (validação)}
		   & \textbf{$\alpha$} & \textbf{\textit{Temperature}} \\
	\hline
	% ResNet-50 	& 	Não 	& 	90.65\%	& 	- 	& 	-	 \\
	% Aluno 		& 	Não 	& 	76.80\%	& 	- 	& 	-	 \\
	Rafael-base 	& 	Não 	& 	71.38\%	& 	- 	& 	-	 \\
	Rafael-1 	& 	Não 	& 	67.08\%	& 	- 	& 	-	 \\
	Rafael-2 	& 	Não 	& 	74.57\%	& 	- 	& 	-	 \\
	Rafael-3 	& 	Não 	& 	71.01\%	& 	- 	& 	-	 \\
	% Aluno 		& 	Sim 	& 	83.79\%	& 	0.1 	& 	5	 \\
	Rafael-base 	& 	Sim 	& 	74.21\%	& 	0.1 	& 	10	 \\
	Rafael-1 	& 	Sim 	& 	69.70\%	& 	0.01 	& 	20	 \\
	Rafael-2 	& 	Sim 	& 	79.12\%	& 	0.01 	& 	7	 \\
	Rafael-3 	& 	Sim 	& 	76.55\%	& 	0.01 	& 	5	 \\
	\hline
\end{tabular}
\legend{Fonte: Autor}
\end{table}
\end{center}

A \autoref{tabela_acuracia_1} apresenta a acurácia dos modelos Rafael-Base, Rafael-1, Rafael-2 e Rafael-3 na tarefa de
classificação na base STL-10.
Onde a coluna \textbf{Com destilação de conhecimento?} indica se a técnica de destilação foi aplicada
ou não, e as colunas $\alpha$ e \textit{Temperature} indicam os valores dos hiperparâmetros utilizados.
Percebe-se que, em todos os casos, os modelos que foram treinados utilizando a técnica de destilação de conhecimento alcançaram
uma acurácia maior do que os modelos treinados apenas com os atributos alvo, chegando a um aumento maior que $5\%$ (no modelo
Rafael-3).
Nela, as variações indicam a quantidade de camadas convolucionais adicionadas, Rafael-1
(\autoref{cap_resultados_rafael_1}) indica que foi adicionada uma camada convolucional $9x9$ no modelo, Rafael-2
(\autoref{cap_resultados_rafael_2}) indica que foi adicionada duas camadas $3x3$ convolucionais e Rafael-3
(\autoref{cap_resultados_rafael_3})indica que foi adicionada três camadas $3x3$.

\begin{figure}
	\caption {\label{cap_resultados_rafael_1}Arquitetura do modelo Rafael-1}
	\begin{center}
		\includegraphics[scale=0.50]{Imagens/arch-rafael-1}
	\end{center}
	\legend {Fonte: Autor}
\end{figure}

\begin{figure}
	\caption {\label{cap_resultados_rafael_2}Arquitetura do modelo Rafael-2}
	\begin{center}
		\includegraphics[scale=0.50]{Imagens/arch-rafael-2}
	\end{center}
	\legend {Fonte: Autor}
\end{figure}

\begin{figure}
	\caption {\label{cap_resultados_rafael_3}Arquitetura do modelo Rafael-3}
	\begin{center}
		\includegraphics[scale=0.50]{Imagens/arch-rafael-3}
	\end{center}
	\legend {Fonte: Autor}
\end{figure}

\section{\textit{Pruning} e Quantização}

Para esse experimento foi utilizada a base CIFAR-10, pois ela exige menos do modelo, facilitando o treinamento de uma
CNN que performe bem nessa tarefa de classificação, o que permite que o foco da atividade seja mantido.
Essa base possui 10 classes, com  6.000 imagens para cada classe, sendo que essas imagens têm resolução igual a
$32x32$ e possui 3 canais de cores (RGB). Nesse conjunto de dados também foi necessário fazer
\textit{data augmentation} para melhorar a acurácia do modelo final.

O modelo utilizado no experimento foi gerado pelo \autoref{pruning_quantization_model}, inicialmente ele possuía
2.397.226 parâmetros (28 MB). Inicialmente ele foi treinado durante 25 \textit{epochs} (épocas), atingindo
uma acurácia de $90.18\%$ nos dados de treinamento e $85.91\%$ nos dados de validação.
Onde somente os dados de validação serão utilizados para comparar os modelos, pois eles podem sofrer
\textit{overfitting} e ter um alto desempenho nos dados de treinamento e baixo desempenho nos dados de validação.

Depois de treinado, o modelo foi podado utilizando a estratégia de \textit{prune low magnitude}
(podar baixa magnitude), que tem como foco zerar valores abaixo de um certo limiar. Depois de definir os parâmetros da
poda, o modelo foi retreinado por 2 \textit{epochs}, para que o algoritmo de poda consiga identificar as conexões
importantes durante o uso do modelo.
Após o retreinamento, o modelo final teve acurácia de $83.83\%$ nos dados de treinamento e $84.40\%$ nos dados de
validação, consumindo 9.3 MB após remover todos os valores iguais a zero.

Depois de podado, o modelo foi convertido para TensorFlow Lite, consumindo 9.2 MB de armazenamento e ficando com
$84.91\%$ de acurácia. Depois disso, a quantização é aplicada utilizando a API do TensorFlow Lite, deixando o modelo
final com 2.4 MB e $84.36\%$ de acurácia.

\begin{center}
\begin{table}[htb]
\centering
\ABNTEXfontereduzida
\caption[Acurácia e peso dos modelos]{Acurácia e peso dos modelos.}
\label{tabela_acuracia_peso}
\begin{tabular}{ |c|c|c| }
	\hline
	\textbf{Modelo} & \textbf{Acurácia (validação)}  & \textbf{\textit{Memory footprint} (MB)} \\
	\hline
	Modelo base 				 & 	85.91\% 	& 	28	\\
	Modelo base podado 			 & 	84.40\% 	& 	9.3	\\
	Modelo base podado (TFLite) 		 & 	84.91\% 	& 	9.2	\\
	Modelo base podado e quantizado (TFLite) & 	84.36\% 	& 	2.4	\\
	\hline
\end{tabular}
\legend{Fonte: Autor}
\end{table}
\end{center}

A \autoref{tabela_acuracia_peso} mostra a acurácia dos modelos (nos dados de validação) durante as etapas de poda e
quantização, onde a coluna \textbf{\textit{Memory footprint}}  indica o consumo de armazenamento do modelo.
A poda e quantização do modelo base resultou em uma redução de pegada de memória de 28 MB para 2.4 MB, apresentando uma perda
de $1.5\%$ da sua acurácia, tornando o modelo mais eficiente sem a perda de desempenho.
